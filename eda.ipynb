{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "783a77b2",
   "metadata": {},
   "source": [
    "KOD DO CZYSZCZENIA MEXICO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "383ffb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Temp - °C</th>\n",
       "      <th>Hum - %</th>\n",
       "      <th>Wind Speed - m/s</th>\n",
       "      <th>SolarRad</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Segment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>29.4</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>799.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>30.4</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>853.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>889.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>31.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>908.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>23.6</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>23.6</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>26.8</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>732.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23469 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Day  Month  Year  Hour  Minute  Temp - °C  Hum - %  Wind Speed - m/s  \\\n",
       "Segment                                                                         \n",
       "1          5      2  2006    19       0       24.3     49.0               0.0   \n",
       "1          6      2  2006    23       0       29.4     37.0               1.3   \n",
       "1          6      2  2006    23      30       30.4     33.0               1.8   \n",
       "1          7      2  2006     0       0       31.1     33.0               1.3   \n",
       "1          7      2  2006     0      30       31.4     30.0               1.8   \n",
       "...      ...    ...   ...   ...     ...        ...      ...               ...   \n",
       "1          9      1  2008     4       0       23.9     83.0               1.3   \n",
       "1          9      1  2008     6       0       23.6     84.0               0.9   \n",
       "1          9      1  2008     8       0       23.6     83.0               0.9   \n",
       "1          9      1  2008    10       0       24.6     71.0               2.2   \n",
       "1          9      1  2008    12       0       26.8     60.0               2.7   \n",
       "\n",
       "         SolarRad  \n",
       "Segment            \n",
       "1             0.0  \n",
       "1           799.0  \n",
       "1           853.0  \n",
       "1           889.0  \n",
       "1           908.0  \n",
       "...           ...  \n",
       "1             0.0  \n",
       "1             0.0  \n",
       "1            22.0  \n",
       "1           306.0  \n",
       "1           732.0  \n",
       "\n",
       "[23469 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "# Describe the name of CSV to be cleaned\n",
    "name_of_file_to_clear = \"Nizanda_just_database.xlsx\"\n",
    "\n",
    "#dataset read\n",
    "df = pd.read_excel(r\"\"+name_of_file_to_clear, index_col=0)\n",
    "                 \n",
    "#dropping data\n",
    "df.drop(\n",
    "['Source', 'Barometer - mm Hg', 'High Temp - °C', 'Low Temp - °C', 'Dew Point - °C', 'Wet Bulb - °C',  'Wind Direction', 'Wind Run - m', 'High Wind Speed - m/s', 'High Wind Direction', 'Wind Chill - °C', 'Heat Index - °C', 'THW Index - °C', 'Rain - mm', 'Rain Rate - mm/h', 'ET - mm', 'Heating Degree Days', 'Cooling Degree Days', 'InTemp', 'InHum', 'In Dew', 'InHeat', 'InEMC', 'In AirDensity', 'WindSamp', 'WindTx ', 'ISSRecept', 'Arc.Int.', 'SolarEnergy', 'HiSolarRad'], axis=1, inplace=True)\n",
    "\n",
    "# remove None and incorrect rows from df\n",
    "df.replace('None', np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# preview cleaned data\n",
    "display(df)\n",
    "\n",
    "# save cleaned data to csv file called Nizanda_cleared.csv\n",
    "df.to_csv(r\"Nizanda_cleared.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1c0a34",
   "metadata": {},
   "source": [
    "DO CZYSZCZENIA BRAZIL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e9e8753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RADIACAO GLOBAL (Kj/m²)</th>\n",
       "      <th>TEMPERATURA DO AR - BULBO SECO, HORARIA (°C)</th>\n",
       "      <th>TEMPERATURA DO PONTO DE ORVALHO (°C)</th>\n",
       "      <th>TEMPERATURA ORVALHO MIN. NA HORA ANT. (AUT) (°C)</th>\n",
       "      <th>region</th>\n",
       "      <th>state</th>\n",
       "      <th>station</th>\n",
       "      <th>VENTO, DIREÇÃO HORARIA (gr) (° (gr))</th>\n",
       "      <th>VENTO, RAJADA MAXIMA (m/s)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138998</th>\n",
       "      <td>3391</td>\n",
       "      <td>26.5</td>\n",
       "      <td>17.7</td>\n",
       "      <td>16.5</td>\n",
       "      <td>CO</td>\n",
       "      <td>DF</td>\n",
       "      <td>PARANOA (COOPA-DF)</td>\n",
       "      <td>39</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138999</th>\n",
       "      <td>3306</td>\n",
       "      <td>26.6</td>\n",
       "      <td>16.7</td>\n",
       "      <td>16.0</td>\n",
       "      <td>CO</td>\n",
       "      <td>DF</td>\n",
       "      <td>PARANOA (COOPA-DF)</td>\n",
       "      <td>55</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139000</th>\n",
       "      <td>3167</td>\n",
       "      <td>27.3</td>\n",
       "      <td>15.8</td>\n",
       "      <td>14.5</td>\n",
       "      <td>CO</td>\n",
       "      <td>DF</td>\n",
       "      <td>PARANOA (COOPA-DF)</td>\n",
       "      <td>62</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139001</th>\n",
       "      <td>3279</td>\n",
       "      <td>27.5</td>\n",
       "      <td>12.9</td>\n",
       "      <td>12.9</td>\n",
       "      <td>CO</td>\n",
       "      <td>DF</td>\n",
       "      <td>PARANOA (COOPA-DF)</td>\n",
       "      <td>43</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139002</th>\n",
       "      <td>2753</td>\n",
       "      <td>27.5</td>\n",
       "      <td>13.7</td>\n",
       "      <td>12.4</td>\n",
       "      <td>CO</td>\n",
       "      <td>DF</td>\n",
       "      <td>PARANOA (COOPA-DF)</td>\n",
       "      <td>98</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138993</th>\n",
       "      <td>29</td>\n",
       "      <td>18.4</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.6</td>\n",
       "      <td>CO</td>\n",
       "      <td>DF</td>\n",
       "      <td>PARANOA (COOPA-DF)</td>\n",
       "      <td>72</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138994</th>\n",
       "      <td>557</td>\n",
       "      <td>20.3</td>\n",
       "      <td>16.9</td>\n",
       "      <td>15.8</td>\n",
       "      <td>CO</td>\n",
       "      <td>DF</td>\n",
       "      <td>PARANOA (COOPA-DF)</td>\n",
       "      <td>69</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138995</th>\n",
       "      <td>1441</td>\n",
       "      <td>21.8</td>\n",
       "      <td>16.6</td>\n",
       "      <td>16.4</td>\n",
       "      <td>CO</td>\n",
       "      <td>DF</td>\n",
       "      <td>PARANOA (COOPA-DF)</td>\n",
       "      <td>83</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138996</th>\n",
       "      <td>2334</td>\n",
       "      <td>23.2</td>\n",
       "      <td>17.3</td>\n",
       "      <td>16.4</td>\n",
       "      <td>CO</td>\n",
       "      <td>DF</td>\n",
       "      <td>PARANOA (COOPA-DF)</td>\n",
       "      <td>59</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138997</th>\n",
       "      <td>3113</td>\n",
       "      <td>25.1</td>\n",
       "      <td>17.4</td>\n",
       "      <td>16.5</td>\n",
       "      <td>CO</td>\n",
       "      <td>DF</td>\n",
       "      <td>PARANOA (COOPA-DF)</td>\n",
       "      <td>50</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11427120 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RADIACAO GLOBAL (Kj/m²)  TEMPERATURA DO AR - BULBO SECO, HORARIA (°C)  \\\n",
       "index                                                                           \n",
       "138998                     3391                                          26.5   \n",
       "138999                     3306                                          26.6   \n",
       "139000                     3167                                          27.3   \n",
       "139001                     3279                                          27.5   \n",
       "139002                     2753                                          27.5   \n",
       "...                         ...                                           ...   \n",
       "138993                       29                                          18.4   \n",
       "138994                      557                                          20.3   \n",
       "138995                     1441                                          21.8   \n",
       "138996                     2334                                          23.2   \n",
       "138997                     3113                                          25.1   \n",
       "\n",
       "        TEMPERATURA DO PONTO DE ORVALHO (°C)  \\\n",
       "index                                          \n",
       "138998                                  17.7   \n",
       "138999                                  16.7   \n",
       "139000                                  15.8   \n",
       "139001                                  12.9   \n",
       "139002                                  13.7   \n",
       "...                                      ...   \n",
       "138993                                  15.8   \n",
       "138994                                  16.9   \n",
       "138995                                  16.6   \n",
       "138996                                  17.3   \n",
       "138997                                  17.4   \n",
       "\n",
       "        TEMPERATURA ORVALHO MIN. NA HORA ANT. (AUT) (°C) region state  \\\n",
       "index                                                                   \n",
       "138998                                              16.5     CO    DF   \n",
       "138999                                              16.0     CO    DF   \n",
       "139000                                              14.5     CO    DF   \n",
       "139001                                              12.9     CO    DF   \n",
       "139002                                              12.4     CO    DF   \n",
       "...                                                  ...    ...   ...   \n",
       "138993                                              15.6     CO    DF   \n",
       "138994                                              15.8     CO    DF   \n",
       "138995                                              16.4     CO    DF   \n",
       "138996                                              16.4     CO    DF   \n",
       "138997                                              16.5     CO    DF   \n",
       "\n",
       "                   station  VENTO, DIREÇÃO HORARIA (gr) (° (gr))  \\\n",
       "index                                                              \n",
       "138998  PARANOA (COOPA-DF)                                    39   \n",
       "138999  PARANOA (COOPA-DF)                                    55   \n",
       "139000  PARANOA (COOPA-DF)                                    62   \n",
       "139001  PARANOA (COOPA-DF)                                    43   \n",
       "139002  PARANOA (COOPA-DF)                                    98   \n",
       "...                    ...                                   ...   \n",
       "138993  PARANOA (COOPA-DF)                                    72   \n",
       "138994  PARANOA (COOPA-DF)                                    69   \n",
       "138995  PARANOA (COOPA-DF)                                    83   \n",
       "138996  PARANOA (COOPA-DF)                                    59   \n",
       "138997  PARANOA (COOPA-DF)                                    50   \n",
       "\n",
       "        VENTO, RAJADA MAXIMA (m/s)  \n",
       "index                               \n",
       "138998                         9.6  \n",
       "138999                         8.3  \n",
       "139000                         8.3  \n",
       "139001                         6.7  \n",
       "139002                         6.4  \n",
       "...                            ...  \n",
       "138993                         3.5  \n",
       "138994                         3.5  \n",
       "138995                         7.6  \n",
       "138996                         7.6  \n",
       "138997                         7.0  \n",
       "\n",
       "[11427120 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "# Describe the name of CSV to be cleaned\n",
    "name_of_file_to_clear = \"central_west.csv\"\n",
    "\n",
    "#dataset read\n",
    "df = pd.read_csv(r\"\"+name_of_file_to_clear, index_col=0)\n",
    "\n",
    "\n",
    "# create new dataframe using only columns 7,8,12,19,20,21,16,17 \n",
    "df = df.iloc[:, [6,7,8,12,19,20,21,16,17]]\n",
    "\n",
    "# Remove rows with nans and incorrect data\n",
    "df.replace('None', np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# save as new csv file called central_west_cleared.csv\n",
    "display(df)\n",
    "df.to_csv(r\"central_west_cleared.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12401388",
   "metadata": {},
   "source": [
    "CZYSZCZENIE PLIKU QZVIN IRAN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcb95894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>relative_humidity_2m</th>\n",
       "      <th>dew_point_2m</th>\n",
       "      <th>apparent_temperature</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>rain</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>snow_depth</th>\n",
       "      <th>weather_code</th>\n",
       "      <th>pressure_msl</th>\n",
       "      <th>...</th>\n",
       "      <th>direct_radiation</th>\n",
       "      <th>diffuse_radiation</th>\n",
       "      <th>direct_normal_irradiance</th>\n",
       "      <th>global_tilted_irradiance</th>\n",
       "      <th>terrestrial_radiation</th>\n",
       "      <th>shortwave_radiation_instant</th>\n",
       "      <th>diffuse_radiation_instant</th>\n",
       "      <th>direct_normal_irradiance_instant</th>\n",
       "      <th>global_tilted_irradiance_instant</th>\n",
       "      <th>terrestrial_radiation_instant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-12-31 20:30:00+00:00</th>\n",
       "      <td>4.965500</td>\n",
       "      <td>54.579082</td>\n",
       "      <td>-3.434500</td>\n",
       "      <td>1.918004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1022.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-12-31 21:30:00+00:00</th>\n",
       "      <td>4.765500</td>\n",
       "      <td>54.118652</td>\n",
       "      <td>-3.734500</td>\n",
       "      <td>1.697024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-12-31 22:30:00+00:00</th>\n",
       "      <td>4.565500</td>\n",
       "      <td>53.861824</td>\n",
       "      <td>-3.984500</td>\n",
       "      <td>1.451427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-12-31 23:30:00+00:00</th>\n",
       "      <td>4.265500</td>\n",
       "      <td>54.388763</td>\n",
       "      <td>-4.134500</td>\n",
       "      <td>1.112651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1022.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:30:00+00:00</th>\n",
       "      <td>4.015500</td>\n",
       "      <td>54.320557</td>\n",
       "      <td>-4.384500</td>\n",
       "      <td>0.833469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1022.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-29 15:30:00+00:00</th>\n",
       "      <td>20.457000</td>\n",
       "      <td>72.320175</td>\n",
       "      <td>15.307000</td>\n",
       "      <td>19.370491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1011.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.233355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-29 16:30:00+00:00</th>\n",
       "      <td>19.857000</td>\n",
       "      <td>73.858010</td>\n",
       "      <td>15.057000</td>\n",
       "      <td>19.190334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1012.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-29 17:30:00+00:00</th>\n",
       "      <td>19.557001</td>\n",
       "      <td>74.283440</td>\n",
       "      <td>14.857000</td>\n",
       "      <td>18.855185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1013.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-29 18:30:00+00:00</th>\n",
       "      <td>19.307001</td>\n",
       "      <td>74.480835</td>\n",
       "      <td>14.657001</td>\n",
       "      <td>18.530184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1013.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-29 19:30:00+00:00</th>\n",
       "      <td>19.257000</td>\n",
       "      <td>71.405754</td>\n",
       "      <td>13.957001</td>\n",
       "      <td>18.625538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1013.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216192 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           temperature_2m  relative_humidity_2m  dew_point_2m  \\\n",
       "date                                                                            \n",
       "1999-12-31 20:30:00+00:00        4.965500             54.579082     -3.434500   \n",
       "1999-12-31 21:30:00+00:00        4.765500             54.118652     -3.734500   \n",
       "1999-12-31 22:30:00+00:00        4.565500             53.861824     -3.984500   \n",
       "1999-12-31 23:30:00+00:00        4.265500             54.388763     -4.134500   \n",
       "2000-01-01 00:30:00+00:00        4.015500             54.320557     -4.384500   \n",
       "...                                   ...                   ...           ...   \n",
       "2024-08-29 15:30:00+00:00       20.457000             72.320175     15.307000   \n",
       "2024-08-29 16:30:00+00:00       19.857000             73.858010     15.057000   \n",
       "2024-08-29 17:30:00+00:00       19.557001             74.283440     14.857000   \n",
       "2024-08-29 18:30:00+00:00       19.307001             74.480835     14.657001   \n",
       "2024-08-29 19:30:00+00:00       19.257000             71.405754     13.957001   \n",
       "\n",
       "                           apparent_temperature  precipitation  rain  \\\n",
       "date                                                                   \n",
       "1999-12-31 20:30:00+00:00              1.918004            0.0   0.0   \n",
       "1999-12-31 21:30:00+00:00              1.697024            0.0   0.0   \n",
       "1999-12-31 22:30:00+00:00              1.451427            0.0   0.0   \n",
       "1999-12-31 23:30:00+00:00              1.112651            0.0   0.0   \n",
       "2000-01-01 00:30:00+00:00              0.833469            0.0   0.0   \n",
       "...                                         ...            ...   ...   \n",
       "2024-08-29 15:30:00+00:00             19.370491            0.0   0.0   \n",
       "2024-08-29 16:30:00+00:00             19.190334            0.0   0.0   \n",
       "2024-08-29 17:30:00+00:00             18.855185            0.0   0.0   \n",
       "2024-08-29 18:30:00+00:00             18.530184            0.0   0.0   \n",
       "2024-08-29 19:30:00+00:00             18.625538            0.0   0.0   \n",
       "\n",
       "                           snowfall  snow_depth  weather_code  pressure_msl  \\\n",
       "date                                                                          \n",
       "1999-12-31 20:30:00+00:00       0.0         0.0           0.0        1022.7   \n",
       "1999-12-31 21:30:00+00:00       0.0         0.0           0.0        1023.0   \n",
       "1999-12-31 22:30:00+00:00       0.0         0.0           0.0        1023.0   \n",
       "1999-12-31 23:30:00+00:00       0.0         0.0           0.0        1022.9   \n",
       "2000-01-01 00:30:00+00:00       0.0         0.0           0.0        1022.6   \n",
       "...                             ...         ...           ...           ...   \n",
       "2024-08-29 15:30:00+00:00       0.0         NaN           2.0        1011.7   \n",
       "2024-08-29 16:30:00+00:00       0.0         NaN           2.0        1012.7   \n",
       "2024-08-29 17:30:00+00:00       0.0         NaN           3.0        1013.1   \n",
       "2024-08-29 18:30:00+00:00       0.0         NaN           2.0        1013.3   \n",
       "2024-08-29 19:30:00+00:00       0.0         NaN           2.0        1013.3   \n",
       "\n",
       "                           ...  direct_radiation  diffuse_radiation  \\\n",
       "date                       ...                                        \n",
       "1999-12-31 20:30:00+00:00  ...               0.0                0.0   \n",
       "1999-12-31 21:30:00+00:00  ...               0.0                0.0   \n",
       "1999-12-31 22:30:00+00:00  ...               0.0                0.0   \n",
       "1999-12-31 23:30:00+00:00  ...               0.0                0.0   \n",
       "2000-01-01 00:30:00+00:00  ...               0.0                0.0   \n",
       "...                        ...               ...                ...   \n",
       "2024-08-29 15:30:00+00:00  ...               0.0                1.0   \n",
       "2024-08-29 16:30:00+00:00  ...               0.0                0.0   \n",
       "2024-08-29 17:30:00+00:00  ...               0.0                0.0   \n",
       "2024-08-29 18:30:00+00:00  ...               0.0                0.0   \n",
       "2024-08-29 19:30:00+00:00  ...               0.0                0.0   \n",
       "\n",
       "                           direct_normal_irradiance  global_tilted_irradiance  \\\n",
       "date                                                                            \n",
       "1999-12-31 20:30:00+00:00                       0.0                       0.0   \n",
       "1999-12-31 21:30:00+00:00                       0.0                       0.0   \n",
       "1999-12-31 22:30:00+00:00                       0.0                       0.0   \n",
       "1999-12-31 23:30:00+00:00                       0.0                       0.0   \n",
       "2000-01-01 00:30:00+00:00                       0.0                       0.0   \n",
       "...                                             ...                       ...   \n",
       "2024-08-29 15:30:00+00:00                       0.0                       1.0   \n",
       "2024-08-29 16:30:00+00:00                       0.0                       0.0   \n",
       "2024-08-29 17:30:00+00:00                       0.0                       0.0   \n",
       "2024-08-29 18:30:00+00:00                       0.0                       0.0   \n",
       "2024-08-29 19:30:00+00:00                       0.0                       0.0   \n",
       "\n",
       "                           terrestrial_radiation  shortwave_radiation_instant  \\\n",
       "date                                                                            \n",
       "1999-12-31 20:30:00+00:00               0.000000                          0.0   \n",
       "1999-12-31 21:30:00+00:00               0.000000                          0.0   \n",
       "1999-12-31 22:30:00+00:00               0.000000                          0.0   \n",
       "1999-12-31 23:30:00+00:00               0.000000                          0.0   \n",
       "2000-01-01 00:30:00+00:00               0.000000                          0.0   \n",
       "...                                          ...                          ...   \n",
       "2024-08-29 15:30:00+00:00              11.233355                          0.0   \n",
       "2024-08-29 16:30:00+00:00               0.000000                          0.0   \n",
       "2024-08-29 17:30:00+00:00               0.000000                          0.0   \n",
       "2024-08-29 18:30:00+00:00               0.000000                          0.0   \n",
       "2024-08-29 19:30:00+00:00               0.000000                          0.0   \n",
       "\n",
       "                           diffuse_radiation_instant  \\\n",
       "date                                                   \n",
       "1999-12-31 20:30:00+00:00                        0.0   \n",
       "1999-12-31 21:30:00+00:00                        0.0   \n",
       "1999-12-31 22:30:00+00:00                        0.0   \n",
       "1999-12-31 23:30:00+00:00                        0.0   \n",
       "2000-01-01 00:30:00+00:00                        0.0   \n",
       "...                                              ...   \n",
       "2024-08-29 15:30:00+00:00                        0.0   \n",
       "2024-08-29 16:30:00+00:00                        0.0   \n",
       "2024-08-29 17:30:00+00:00                        0.0   \n",
       "2024-08-29 18:30:00+00:00                        0.0   \n",
       "2024-08-29 19:30:00+00:00                        0.0   \n",
       "\n",
       "                           direct_normal_irradiance_instant  \\\n",
       "date                                                          \n",
       "1999-12-31 20:30:00+00:00                               0.0   \n",
       "1999-12-31 21:30:00+00:00                               0.0   \n",
       "1999-12-31 22:30:00+00:00                               0.0   \n",
       "1999-12-31 23:30:00+00:00                               0.0   \n",
       "2000-01-01 00:30:00+00:00                               0.0   \n",
       "...                                                     ...   \n",
       "2024-08-29 15:30:00+00:00                               0.0   \n",
       "2024-08-29 16:30:00+00:00                               0.0   \n",
       "2024-08-29 17:30:00+00:00                               0.0   \n",
       "2024-08-29 18:30:00+00:00                               0.0   \n",
       "2024-08-29 19:30:00+00:00                               0.0   \n",
       "\n",
       "                           global_tilted_irradiance_instant  \\\n",
       "date                                                          \n",
       "1999-12-31 20:30:00+00:00                               0.0   \n",
       "1999-12-31 21:30:00+00:00                               0.0   \n",
       "1999-12-31 22:30:00+00:00                               0.0   \n",
       "1999-12-31 23:30:00+00:00                               0.0   \n",
       "2000-01-01 00:30:00+00:00                               0.0   \n",
       "...                                                     ...   \n",
       "2024-08-29 15:30:00+00:00                               0.0   \n",
       "2024-08-29 16:30:00+00:00                               0.0   \n",
       "2024-08-29 17:30:00+00:00                               0.0   \n",
       "2024-08-29 18:30:00+00:00                               0.0   \n",
       "2024-08-29 19:30:00+00:00                               0.0   \n",
       "\n",
       "                           terrestrial_radiation_instant  \n",
       "date                                                      \n",
       "1999-12-31 20:30:00+00:00                            0.0  \n",
       "1999-12-31 21:30:00+00:00                            0.0  \n",
       "1999-12-31 22:30:00+00:00                            0.0  \n",
       "1999-12-31 23:30:00+00:00                            0.0  \n",
       "2000-01-01 00:30:00+00:00                            0.0  \n",
       "...                                                  ...  \n",
       "2024-08-29 15:30:00+00:00                            0.0  \n",
       "2024-08-29 16:30:00+00:00                            0.0  \n",
       "2024-08-29 17:30:00+00:00                            0.0  \n",
       "2024-08-29 18:30:00+00:00                            0.0  \n",
       "2024-08-29 19:30:00+00:00                            0.0  \n",
       "\n",
       "[216192 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "# Describe the name of CSV to be cleaned\n",
    "name_of_file_to_clear = \"qzvin_hourly_data.csv\"\n",
    "\n",
    "#dataset read\n",
    "df = pd.read_csv(r\"\"+name_of_file_to_clear, index_col=0)\n",
    "\n",
    "\n",
    "# create new dataframe using only columns 7,8,12,19,20,21,16,17 \n",
    "#df = df.iloc[:, [6,7,8,12,19,20,21,16,17]]\n",
    "\n",
    "# Remove rows with nans and incorrect data\n",
    "#df.replace('None', np.nan, inplace=True)\n",
    "#df.dropna(inplace=True)\n",
    "\n",
    "# save as new csv file called central_west_cleared.csv\n",
    "display(df)\n",
    "#df.to_csv(r\"central_west_cleared.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98add477",
   "metadata": {},
   "source": [
    "UZYSKAJ ARCHIWALNE DANE POGODOWE DLA LOKALIZACJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5623cce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for site: Gdańsk (54.352, 18.6466) from 2023-01-01 to 2023-12-31\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Open-Meteo API error 400: {\"reason\":\"Data corrupted at path ''. Cannot initialize SurfacePressureAndHeightVariable<VariableAndPreviousDay, ForecastPressureVariable, ForecastHeightVariable> from invalid String value temperature_2m,surface_pressure,shortwave_radiation,windspeed_10m,windspeed_100m,winddirection_10m,winddirection_100m,windgusts_10m,relativehumidity_2m,sunshine_duration,ghi,dni,dhi,gti,cloudcover_high,cloudcover_mid,cloudcover_low,cloudcover.\",\"error\":true}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 223\u001b[39m\n\u001b[32m    220\u001b[39m end_date = row[\u001b[33m'\u001b[39m\u001b[33mend_date\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    222\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDownloading data for site: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msite_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlat\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlon\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m weather_df = \u001b[43mget_open_meteo_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    225\u001b[39m output_filename = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mweather_data_downloaded/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msite_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_weather_data.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    226\u001b[39m weather_df.to_csv(output_filename)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 141\u001b[39m, in \u001b[36mget_open_meteo_archive\u001b[39m\u001b[34m(lat, lon, start_date, end_date, timezone)\u001b[39m\n\u001b[32m    139\u001b[39m resp = requests.get(OPEN_METEO_ARCHIVE_ENDPOINT, params=params, timeout=\u001b[32m30\u001b[39m)\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resp.status_code != \u001b[32m200\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOpen-Meteo API error \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp.text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    143\u001b[39m j = resp.json()\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mhourly\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m j \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m j[\u001b[33m\"\u001b[39m\u001b[33mhourly\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    145\u001b[39m     \u001b[38;5;66;03m# If the API returns no hourly data for this chunk, skip\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Open-Meteo API error 400: {\"reason\":\"Data corrupted at path ''. Cannot initialize SurfacePressureAndHeightVariable<VariableAndPreviousDay, ForecastPressureVariable, ForecastHeightVariable> from invalid String value temperature_2m,surface_pressure,shortwave_radiation,windspeed_10m,windspeed_100m,winddirection_10m,winddirection_100m,windgusts_10m,relativehumidity_2m,sunshine_duration,ghi,dni,dhi,gti,cloudcover_high,cloudcover_mid,cloudcover_low,cloudcover.\",\"error\":true}"
     ]
    }
   ],
   "source": [
    "# get_open_meteo_archive.py\n",
    "\"\"\"\n",
    "Fetch hourly archival weather variables from Open-Meteo and return a pandas DataFrame.\n",
    "\n",
    "Dependencies:\n",
    "  pip install requests pandas\n",
    "\n",
    "Function:\n",
    "  get_open_meteo_archive(lat, lon, start_date, end_date, timezone='UTC')\n",
    "\n",
    "Inputs:\n",
    "  - lat: float latitude\n",
    "  - lon: float longitude\n",
    "  - start_date: str 'YYYY-MM-DD'\n",
    "  - end_date: str   'YYYY-MM-DD'\n",
    "  - timezone: optional timezone string to request (default 'UTC')\n",
    "\n",
    "Returns:\n",
    "  pandas.DataFrame indexed by UTC datetime with columns:\n",
    "    temperature_2m,\n",
    "    surface_pressure,\n",
    "    solar_radiation,\n",
    "    windspeed_10m,\n",
    "    windspeed_100m,\n",
    "    winddirection_10m,\n",
    "    winddirection_100m,\n",
    "    windgusts_10m,\n",
    "    relativehumidity_2m,\n",
    "    sunshine_duration,\n",
    "    ghi,\n",
    "    dni,\n",
    "    dhi,\n",
    "    gti,\n",
    "    clouds_high,\n",
    "    clouds_mid,\n",
    "    clouds_low,\n",
    "    clouds_total\n",
    "\n",
    "Notes:\n",
    "  - The Open-Meteo archive API may limit the maximum span per request. This function will chunk requests in 31-day windows.\n",
    "  - Some variables may not exist for all regions or API configurations. Missing variables will be NaN.\n",
    "  - If you want GTI computed for a surface tilt/azimuth, additional parameters might be required by the API; adjust accordingly.\n",
    "\"\"\"\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any\n",
    "import requests\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "OPEN_METEO_ARCHIVE_ENDPOINT = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "# Mapping of output column names -> possible Open-Meteo hourly variable names (aliases)\n",
    "_OUTPUT_VAR_ALIASES: Dict[str, List[str]] = {\n",
    "    \"temperature_2m\": [\"temperature_2m\"],\n",
    "    \"surface_pressure\": [\"surface_pressure\"],\n",
    "    # general solar / shortwave aliases\n",
    "    \"solar_radiation\": [\"shortwave_radiation\", \"surface_solar_radiation_downwards\"],\n",
    "    \"windspeed_10m\": [\"windspeed_10m\"],\n",
    "    \"windspeed_100m\": [\"windspeed_100m\"],\n",
    "    \"winddirection_10m\": [\"winddirection_10m\"],\n",
    "    \"winddirection_100m\": [\"winddirection_100m\"],\n",
    "    \"windgusts_10m\": [\"windgusts_10m\"],\n",
    "    \"relativehumidity_2m\": [\"relativehumidity_2m\"],\n",
    "    \"sunshine_duration\": [\"sunshine_duration\"],\n",
    "    # Irradiance variables: GHI / DNI / DHI common names\n",
    "    \"ghi\": [\"ghi\", \"surface_solar_radiation_downwards\", \"shortwave_radiation\"],\n",
    "    \"dni\": [\"dni\", \"direct_normal_irradiance\", \"direct_radiation\"],\n",
    "    \"dhi\": [\"dhi\", \"diffuse_radiation\"],\n",
    "    # GTI (global tilted irradiance) aliases - may require tilt params on some endpoints\n",
    "    \"gti\": [\"gti\", \"global_tilted_irradiance\"],\n",
    "    # Clouds\n",
    "    \"clouds_high\": [\"cloudcover_high\", \"high_clouds\", \"clouds_high\"],\n",
    "    \"clouds_mid\": [\"cloudcover_mid\", \"mid_clouds\", \"clouds_mid\"],\n",
    "    \"clouds_low\": [\"cloudcover_low\", \"low_clouds\", \"clouds_low\"],\n",
    "    \"clouds_total\": [\"cloudcover\", \"clouds\", \"total_clouds\"],\n",
    "}\n",
    "\n",
    "def _chunk_date_ranges(start_date: datetime, end_date: datetime, max_days: int = 31):\n",
    "    \"\"\"\n",
    "    Yield (chunk_start_date, chunk_end_date) tuples inclusive, each range <= max_days.\n",
    "    \"\"\"\n",
    "    cur = start_date\n",
    "    while cur <= end_date:\n",
    "        chunk_end = min(end_date, cur + timedelta(days=max_days - 1))\n",
    "        yield cur.date().isoformat(), chunk_end.date().isoformat()\n",
    "        cur = chunk_end + timedelta(days=1)\n",
    "\n",
    "def _collect_hourly_variable_list() -> List[str]:\n",
    "    \"\"\"Return a deduplicated list of preferred alias names to request from the API.\n",
    "    Prefer the first alias for each output variable and remove duplicates preserving order.\n",
    "    \"\"\"\n",
    "    vars_pref: List[str] = []\n",
    "    for aliases in _OUTPUT_VAR_ALIASES.values():\n",
    "        if not aliases:\n",
    "            continue\n",
    "        primary = aliases[0]\n",
    "        if primary not in vars_pref:\n",
    "            vars_pref.append(primary)\n",
    "    return vars_pref\n",
    "\n",
    "def get_open_meteo_archive(lat: float, lon: float, start_date: str, end_date: str, timezone: str = \"UTC\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch hourly archival data from Open-Meteo and return a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "      lat (float): latitude\n",
    "      lon (float): longitude\n",
    "      start_date (str): 'YYYY-MM-DD'\n",
    "      end_date (str): 'YYYY-MM-DD'\n",
    "      timezone (str): timezone for returned timestamps (default 'UTC')\n",
    "\n",
    "    Returns:\n",
    "      pandas.DataFrame indexed by DatetimeIndex (UTC) with the output columns specified in the module docstring.\n",
    "    \"\"\"\n",
    "    # Validate dates\n",
    "    try:\n",
    "        dt_start = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "        dt_end = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"start_date and end_date must be in YYYY-MM-DD format\")\n",
    "    if dt_end < dt_start:\n",
    "        raise ValueError(\"end_date must be >= start_date\")\n",
    "\n",
    "    hourly_vars = _collect_hourly_variable_list()\n",
    "    hourly_param = \",\".join(hourly_vars)\n",
    "\n",
    "    frames: List[pd.DataFrame] = []\n",
    "\n",
    "    for chunk_start, chunk_end in _chunk_date_ranges(dt_start, dt_end, max_days=31):\n",
    "        params = {\n",
    "            \"latitude\": lat,\n",
    "            \"longitude\": lon,\n",
    "            \"start_date\": chunk_start,\n",
    "            \"end_date\": chunk_end,\n",
    "            \"hourly\": hourly_param,\n",
    "            \"timezone\": timezone\n",
    "        }\n",
    "        resp = requests.get(OPEN_METEO_ARCHIVE_ENDPOINT, params=params, timeout=30)\n",
    "        if resp.status_code != 200:\n",
    "            raise RuntimeError(f\"Open-Meteo API error {resp.status_code}: {resp.text}\")\n",
    "\n",
    "        j = resp.json()\n",
    "        if \"hourly\" not in j or \"time\" not in j[\"hourly\"]:\n",
    "            # If the API returns no hourly data for this chunk, skip\n",
    "            continue\n",
    "\n",
    "        hourly = j[\"hourly\"]\n",
    "        time_vals = hourly.get(\"time\", [])\n",
    "        if len(time_vals) == 0:\n",
    "            continue\n",
    "\n",
    "        df_chunk = pd.DataFrame(index=pd.to_datetime(time_vals))\n",
    "        # Ensure index has timezone if requested; pandas will keep tz-aware string parse; we'll normalize to UTC at the end\n",
    "        for out_col, aliases in _OUTPUT_VAR_ALIASES.items():\n",
    "            # find the first alias that exists in response hourly keys\n",
    "            found_series = None\n",
    "            for alias in aliases:\n",
    "                if alias in hourly:\n",
    "                    found_series = hourly[alias]\n",
    "                    break\n",
    "            if found_series is not None:\n",
    "                # Ensure same length as time, or pad/trim accordingly\n",
    "                series = pd.Series(found_series, index=pd.to_datetime(time_vals))\n",
    "                series.name = out_col\n",
    "                df_chunk[out_col] = series\n",
    "            else:\n",
    "                # Variable not present in this API response; create NaN series\n",
    "                df_chunk[out_col] = pd.Series([float(\"nan\")] * len(time_vals), index=pd.to_datetime(time_vals))\n",
    "\n",
    "        frames.append(df_chunk)\n",
    "\n",
    "    if not frames:\n",
    "        # no data returned\n",
    "        # return empty dataframe with requested columns and index empty\n",
    "        empty_idx = pd.DatetimeIndex([], dtype=\"datetime64[ns, UTC]\")\n",
    "        empty_df = pd.DataFrame(index=empty_idx, columns=list(_OUTPUT_VAR_ALIASES.keys()))\n",
    "        return empty_df\n",
    "\n",
    "    # concat and deduplicate index\n",
    "    df_all = pd.concat(frames)\n",
    "    # Convert index to timezone-aware UTC if not already\n",
    "    try:\n",
    "        # If strings included timezone info, pandas might already have tz; otherwise set tz to provided timezone and convert to UTC.\n",
    "        if df_all.index.tz is None:\n",
    "            # assume they were requested in 'timezone' string; localize then convert to UTC\n",
    "            # if timezone was 'UTC', this will set tzinfo correctly\n",
    "            df_all.index = df_all.index.tz_localize(timezone).tz_convert(\"UTC\")\n",
    "        else:\n",
    "            df_all.index = df_all.index.tz_convert(\"UTC\")\n",
    "        # finally remove tz info (or keep tz-aware index — here we keep tz-aware)\n",
    "    except Exception:\n",
    "        # fallback: parse naive to UTC\n",
    "        df_all.index = pd.to_datetime(df_all.index, utc=True)\n",
    "\n",
    "    # sort and drop duplicates keeping first\n",
    "    df_all = df_all.sort_index().loc[~df_all.index.duplicated(keep=\"first\")]\n",
    "\n",
    "    # Re-order columns deterministically\n",
    "    ordered_cols = list(_OUTPUT_VAR_ALIASES.keys())\n",
    "    for c in ordered_cols:\n",
    "        if c not in df_all.columns:\n",
    "            df_all[c] = float(\"nan\")\n",
    "    df_all = df_all[ordered_cols]\n",
    "\n",
    "    # Reset name of index\n",
    "    df_all.index.name = \"time_utc\"\n",
    "\n",
    "    return df_all\n",
    "\n",
    "# take input data from csv \"input_for_weather_archive_download.csv\" file with columns: name_of_site, latitude, longitude, start_date, end_date \n",
    "# and download weather data for each site and save every site data to separate csv file named \"<name_of_site>_weather_data.csv\" in folder \"weather_data_downloaded/\"\n",
    "if __name__ == \"__main__\":\n",
    "    input_df = pd.read_csv(\"input_for_weather_archive_download.csv\")\n",
    "    for idx, row in input_df.iterrows():\n",
    "        site_name = row['name_of_site']\n",
    "        lat = float(row['latitude'])\n",
    "        lon = float(row['longitude'])\n",
    "        start_date = row['start_date']\n",
    "        end_date = row['end_date']\n",
    "        \n",
    "        print(f\"Downloading data for site: {site_name} ({lat}, {lon}) from {start_date} to {end_date}\")\n",
    "        weather_df = get_open_meteo_archive(lat, lon, start_date, end_date)\n",
    "        \n",
    "        output_filename = f\"weather_data_downloaded/{site_name}_weather_data.csv\"\n",
    "        weather_df.to_csv(output_filename)\n",
    "        print(f\"Saved data to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058436eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Kod do pobrania danych archiwalnych o efektywności wiatraków "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19e7710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import urllib.parse\n",
    "import time\n",
    "\n",
    "API_KEY = \"{{YOUR_API_KEY}}\"\n",
    "EMAIL = \"karolinabudrewicz2003@gmail.com\"\n",
    "BASE_URL = \"https://developer.nrel.gov/api/nsrdb/v2/solar/himawari-download.json?\"\n",
    "POINTS = [\n",
    "'1281027'\n",
    "]\n",
    "\n",
    "def main():\n",
    "    input_data = {\n",
    "        'attributes': 'cloud_type,wind_direction,wind_speed,relative_humidity,air_temperature,surface_pressure,surface_albedo',\n",
    "        'interval': '30',\n",
    "        \n",
    "        'api_key': API_KEY,\n",
    "        'email': EMAIL,\n",
    "    }\n",
    "    for name in ['2020']:\n",
    "        print(f\"Processing name: {name}\")\n",
    "        for id, location_ids in enumerate(POINTS):\n",
    "            input_data['names'] = [name]\n",
    "            input_data['location_ids'] = location_ids\n",
    "            print(f'Making request for point group {id + 1} of {len(POINTS)}...')\n",
    "\n",
    "            if '.csv' in BASE_URL:\n",
    "                url = BASE_URL + urllib.parse.urlencode(data, True)\n",
    "                # Note: CSV format is only supported for single point requests\n",
    "                # Suggest that you might append to a larger data frame\n",
    "                data = pd.read_csv(url)\n",
    "                print(f'Response data (you should replace this print statement with your processing): {data}')\n",
    "                # You can use the following code to write it to a file\n",
    "                # data.to_csv('SingleBigDataPoint.csv')\n",
    "            else:\n",
    "                headers = {\n",
    "                  'x-api-key': API_KEY\n",
    "                }\n",
    "                data = get_response_json_and_handle_errors(requests.post(BASE_URL, input_data, headers=headers))\n",
    "                download_url = data['outputs']['downloadUrl']\n",
    "                # You can do with what you will the download url\n",
    "                print(data['outputs']['message'])\n",
    "                print(f\"Data can be downloaded from this url when ready: {download_url}\")\n",
    "\n",
    "                # Delay for 1 second to prevent rate limiting\n",
    "                time.sleep(1)\n",
    "            print(f'Processed')\n",
    "\n",
    "\n",
    "def get_response_json_and_handle_errors(response: requests.Response) -> dict:\n",
    "    \"\"\"Takes the given response and handles any errors, along with providing\n",
    "    the resulting json\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    response : requests.Response\n",
    "        The response object\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        The resulting json\n",
    "    \"\"\"\n",
    "    if response.status_code != 200:\n",
    "        print(f\"An error has occurred with the server or the request. The request response code/status: {response.status_code} {response.reason}\")\n",
    "        print(f\"The response body: {response.text}\")\n",
    "        exit(1)\n",
    "\n",
    "    try:\n",
    "        response_json = response.json()\n",
    "    except:\n",
    "        print(f\"The response couldn't be parsed as JSON, likely an issue with the server, here is the text: {response.text}\")\n",
    "        exit(1)\n",
    "\n",
    "    if len(response_json['errors']) > 0:\n",
    "        errors = '\\n'.join(response_json['errors'])\n",
    "        print(f\"The request errored out, here are the errors: {errors}\")\n",
    "        exit(1)\n",
    "    return response_json\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f636a072",
   "metadata": {},
   "source": [
    "Clearing the dataset in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1dd673e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PVDAQPVTechnology'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\karol\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'PVDAQPVTechnology'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m     filtered.to_csv(\u001b[33m\"\u001b[39m\u001b[33mResluts_cleared.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m     15\u001b[39m     df = robust_read_csv(\u001b[33m\"\u001b[39m\u001b[33mresult.csv\u001b[39m\u001b[33m\"\u001b[39m, sep=\u001b[33m\"\u001b[39m\u001b[33m;\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     df[\u001b[33m\"\u001b[39m\u001b[33mPVDAQPVTechnology\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPVDAQPVTechnology\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.fillna(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).str.strip()\n\u001b[32m     17\u001b[39m     df[\u001b[33m\"\u001b[39m\u001b[33mPVDAQArray Configuration\u001b[39m\u001b[33m\"\u001b[39m] = df[\u001b[33m\"\u001b[39m\u001b[33mPVDAQArray Configuration\u001b[39m\u001b[33m\"\u001b[39m].fillna(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).str.strip()\n\u001b[32m     20\u001b[39m     mask = df[\u001b[33m\"\u001b[39m\u001b[33mPVDAQPVTechnology\u001b[39m\u001b[33m\"\u001b[39m].isin(ALLOWED_TECH) & df[\u001b[33m\"\u001b[39m\u001b[33mPVDAQArray Configuration\u001b[39m\u001b[33m\"\u001b[39m].isin(ALLOWED_CONFIG)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\karol\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\karol\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'PVDAQPVTechnology'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ALLOWED_TECH = {\"Mono-Si\"}            # example: {\"Mono-Si\", \"CIGS\"}\n",
    "ALLOWED_CONFIG = {\"Fixed Roof\", \"Fixed Ground\"}\n",
    "\n",
    "def robust_read_csv(path, **kwargs):\n",
    "    for enc in (\"utf-8\", \"utf-8-sig\", \"cp1250\", \"cp1252\", \"latin-1\", \"iso-8859-1\"):\n",
    "        try:\n",
    "            return pd.read_csv(path, encoding=enc, **kwargs)\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    return pd.read_csv(path, encoding=\"utf-8\", encoding_errors=\"replace\", **kwargs)\n",
    "\n",
    "def main():\n",
    "    df = robust_read_csv(\"result.csv\", sep=\";\")\n",
    "    df[\"PVDAQPVTechnology\"] = df[\"PVDAQPVTechnology\"].fillna(\"\").str.strip()\n",
    "    df[\"PVDAQArray Configuration\"] = df[\"PVDAQArray Configuration\"].fillna(\"\").str.strip()\n",
    "\n",
    "\n",
    "    mask = df[\"PVDAQPVTechnology\"].isin(ALLOWED_TECH) & df[\"PVDAQArray Configuration\"].isin(ALLOWED_CONFIG)\n",
    "    filtered = df.loc[mask]\n",
    "\n",
    "    filtered.to_csv(\"Resluts_cleared.csv\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e894ce1c",
   "metadata": {},
   "source": [
    "Deeper cleaning the csv file resluts_clearted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4498e71",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'system_public_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\karol\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'system_public_name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m df = pd.read_csv(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m+name_of_file_to_clear, index_col=\u001b[32m0\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m#leave out from the csv file the rows Commercial - NOLA, Mercury Solar Systems - Array 5, Mercury Solar Systems - Array 4, Maui Ocean Center, Farm Solar Array from the system_public_name column\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m df = df[~\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msystem_public_name\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.isin([\u001b[33m'\u001b[39m\u001b[33mCommercial - NOLA\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mMercury Solar Systems - Array 5\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mMercury Solar Systems - Array 4\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mMaui Ocean Center\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mFarm Solar Array\u001b[39m\u001b[33m'\u001b[39m])]\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m#save csv file to a new filled file called Proper_results_cleared.csv\u001b[39;00m\n\u001b[32m     12\u001b[39m df.to_csv(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProper_results_cleared.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\karol\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\karol\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'system_public_name'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#describe the name of CSV to be cleaned\n",
    "name_of_file_to_clear = \"Resluts_cleared.csv\"\n",
    "\n",
    "#dataset read\n",
    "df = pd.read_csv(r\"\"+name_of_file_to_clear, index_col=0)\n",
    "\n",
    "#leave out from the csv file the rows Commercial - NOLA, Mercury Solar Systems - Array 5, Mercury Solar Systems - Array 4, Maui Ocean Center, Farm Solar Array from the system_public_name column\n",
    "df = df[~df['system_public_name'].isin(['Commercial - NOLA', 'Mercury Solar Systems - Array 5', 'Mercury Solar Systems - Array 4', 'Maui Ocean Center', 'Farm Solar Array'])]\n",
    "\n",
    "#save csv file to a new filled file called Proper_results_cleared.csv\n",
    "df.to_csv(r\"Proper_results_cleared.csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
